import streamlit as st
import google.generativeai as genai
import os

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="Honda AI", page_icon="ğŸ¤–", layout="centered")

# --- Ø§Ù„ØªØµÙ…ÙŠÙ… ---
st.markdown("""
<style>
    .stChatMessage {text-align: right; direction: rtl;}
    p {text-align: right; direction: rtl;}
    .stTextInput > div > div > input {text-align: right; direction: rtl;}
    /* Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…Ø²Ø¹Ø¬Ø© */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

st.title("ğŸ¤– Ù‡ÙˆÙ†Ø¯Ø§ - Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠ")

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø°ÙƒÙŠ (Ø§Ù„Ù…ØµØ­Ø­Ø©) ---
def get_auto_model():
    try:
        if "HONDA_API_KEY" not in st.secrets:
            st.error("âš ï¸ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Secrets!")
            return None, "No Key"

        api_key = st.secrets["HONDA_API_KEY"]
        genai.configure(api_key=api_key)
        
        # 1. Ù†Ø³Ø£Ù„ Ø¬ÙˆØ¬Ù„: Ø¥ÙŠÙ‡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù„ÙŠ Ø´ØºØ§Ù„Ø©ØŸ
        available_models = []
        try:
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    available_models.append(m.name)
        except Exception as e:
            st.warning(f"Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ø¬ÙŠØ¨ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©ØŒ Ù‡Ø¬Ø±Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©. Ø§Ù„Ø®Ø·Ø£: {e}")
        
        # 2. Ù†Ø®ØªØ§Ø± Ø§Ù„Ø£ÙØ¶Ù„ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ (ØªØ¹Ø¯ÙŠÙ„ Ù‡Ø§Ù…: Ø¨Ù†Ø¬Ø¨Ø±Ù‡ ÙŠØ®ØªØ§Ø± Ø§Ù„ÙÙ„Ø§Ø´ Ø¹Ø´Ø§Ù† Ø§Ù„ÙƒÙˆØªØ§)
        # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¯ÙŠ Ù…Ø±ØªØ¨Ø© Ù…Ù† Ø§Ù„Ø£Ø³Ø±Ø¹ ÙˆØ§Ù„Ø£ÙˆÙØ± Ù„Ù„Ø£Ø«Ù‚Ù„
        preferences = [
            'models/gemini-2.5-flash',
            'models/gemini-2.5-flash-latest',
            'models/gemini-2.5-flash-001',
            'models/gemini-2.5-pro',
            'models/gemini-2-flash',
            'models/gemini-2-flash-latest',
            'models/gemini-2-flash-001',
            'models/gemini-2-pro',
            'models/gemini-3-flash',
            'models/gemini-3-flash-latest',
            'models/gemini-3-flash-001',
            'models/gemini-3-pro',
            'models/gemini-1.5-flash',
            'models/gemini-1.5-flash-latest',
            'models/gemini-1.5-flash-001',
            'models/gemini-1.5-pro',
            'models/gemini-pro'
        ]
            if not selected_name:
                selected_name = available_models[0]
        else:
            # Ù„Ùˆ ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©ØŒ Ø¬Ø±Ø¨ Ø§Ù„ÙÙ„Ø§Ø´ ÙˆØ®Ù„Ø§Øµ
            selected_name = 'models/gemini-1.5-flash'
        
        return genai.GenerativeModel(selected_name), selected_name

    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¬ÙˆØ¬Ù„: {e}")
        return None, str(e)

# --- ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø® ---
model, model_name = get_auto_model()

if model:
    st.caption(f"âœ… Ù…ØªØµÙ„ Ø¨Ù…Ø®: {model_name}")
else:
    st.caption("ğŸ”´ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ù…ØªØµÙ„")

# --- Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ø´Ø§Øª ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- Ø§Ù„ØªÙØ§Ø¹Ù„ ---
if prompt := st.chat_input("Ø§Ø·Ù„Ø¨ Ù…Ù†ÙŠ Ø£ÙŠ Ø­Ø§Ø¬Ø©..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        if not model:
            message_placeholder.error("Ø£Ù†Ø§ Ø¹Ø·Ù„Ø§Ù† Ø­Ø§Ù„ÙŠØ§Ù‹ Ø¨Ø³Ø¨Ø¨ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„.")
        else:
            try:
                # --- Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ø°ÙƒÙŠ: Ù‡Ù„ Ø¯Ù‡ Ø·Ù„Ø¨ ØªØ·ÙˆÙŠØ±ØŸ ---
                dev_keywords = ["Ø·ÙˆØ±", "Ø¹Ø¯Ù„", "Ø¶ÙŠÙ", "Ø§Ù…Ø³Ø­", "ØºÙŠØ±", "ÙƒÙˆØ¯", "Ø¨Ø±Ù†Ø§Ù…Ø¬", "Ø²Ø±Ø§Ø±", "Ø®Ø§ØµÙŠØ©"]
                is_dev_request = any(word in prompt for word in dev_keywords)

                if is_dev_request:
                    message_placeholder.warning("âš™ï¸ Ø¬Ø§Ø±ÙŠ ÙƒØªØ§Ø¨Ø© ÙƒÙˆØ¯ Ø§Ù„ØªØ·ÙˆÙŠØ±...")
                    
                    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ (Ø¹Ø´Ø§Ù† ÙŠØ¹Ø¯Ù„ Ø¹Ù„ÙŠÙ‡)
                    try:
                        current_file = os.path.basename(__file__)
                        with open(current_file, "r", encoding="utf-8") as f:
                            old_code = f.read()
                    except:
                        old_code = "# Code file read error"

                    # Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØµØ§Ø±Ù… (Ø¹Ø´Ø§Ù† ÙŠÙƒØªØ¨ ÙƒÙˆØ¯ Ø¨Ø¬Ø¯)
                    dev_prompt = f"""
                    ROLE: You are an expert Python Streamlit Developer.
                    TASK: Rewrite the following code to implement this user request: "{prompt}".
                    CURRENT CODE:
                    ```python
                    {old_code}
                    ```
                    RULES:
                    1. RETURN ONLY THE FULL PYTHON CODE. NO EXPLANATION.
                    2. Keep the 'api_key' handling and 'get_auto_model' logic safe.
                    3. If adding a feature (like file upload), use st.file_uploader.
                    """
                    
                    response = model.generate_content(dev_prompt)
                    new_code = response.text.replace("```python", "").replace("```", "").strip()
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
                    message_placeholder.code(new_code, language='python')
                    st.session_state.messages.append({"role": "assistant", "content": "ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯! Ø§Ù†Ø³Ø®Ù‡ ÙˆØ­Ø·Ù‡ ÙÙŠ GitHub Ø¹Ø´Ø§Ù† ÙŠØªØ·Ø¨Ù‚."})
                
                else:
                    # --- Ø¯Ø±Ø¯Ø´Ø© Ø¹Ø§Ø¯ÙŠØ© ---
                    chat_prompt = f"Ø£Ù†Øª Ù‡ÙˆÙ†Ø¯Ø§ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ±ÙŠ Ø°ÙƒÙŠ. Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {prompt}"
                    response = model.generate_content(chat_prompt)
                    message_placeholder.markdown(response.text)
                    st.session_state.messages.append({"role": "assistant", "content": response.text})

            except Exception as e:
                st.error(f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø±Ø¯: {e}")
