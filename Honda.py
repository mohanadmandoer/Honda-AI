import streamlit as st
import google.generativeai as genai
import os

def get_working_model():
    """ÙŠØªØµÙ„ Ø¨Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ Ù…ØªØ§Ø­ (Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ù†Ø§Ø¹Ø© Ø¶Ø¯ Ø§Ù„ØªÙˆÙ‚Ù)"""
    try:
        if "HONDA_API_KEY" not in st.secrets:
            st.error("âš ï¸ Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ´ØºÙŠÙ„ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Secrets!")
            return None, "No Key"

        api_key = st.secrets["HONDA_API_KEY"]
        genai.configure(api_key=api_key)

        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø© (Ø§Ù„Ø­Ø§Ø¶Ø± ÙˆØ§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„)
        models_to_try = [
            'gemini-2.5-flash',
            'gemini-2.5-flash-latest',
            'gemini-2.5-pro',
            'gemini-2.0-flash',
            'gemini-1.5-flash',
            'gemini-1.5-flash-latest',
            'gemini-1.5-pro',
            'gemini-3-flash',
            'gemini-3-flash-latest',
            'gemini-3-pro',
            'gemini-pro',
            'models/gemini-1.5-flash', 'models/gemini-pro'
        ]

        for model_name in models_to_try:
            try:
                model = genai.GenerativeModel(model_name)
                return model, model_name
            except:
                continue 
        
        return genai.GenerativeModel('gemini-1.5-flash'), 'Fallback'

    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return None, str(e)

# ================= ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… =================

st.title("ğŸ¤– Ù‡ÙˆÙ†Ø¯Ø§ - Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…ØªØ·ÙˆØ±")
st.caption("Ø£Ù†Ø§ Ø£Ø·ÙˆØ± Ù†ÙØ³ÙŠØŒ Ø£ØµÙ†Ø¹ Ø§Ù„Ù…Ù„ÙØ§ØªØŒ ÙˆØ£ØªØ­ÙƒÙ… ÙÙŠ Ù…Ø¸Ù‡Ø±ÙŠ.")

# --- Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ (Ù„Ù„Ø£Ø¯ÙˆØ§Øª) ---
with st.sidebar:
    st.header("ğŸ“‚ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù„ÙØ§Øª")
    uploaded_file = st.file_uploader("Ø§Ø¹Ø·Ù†ÙŠ Ù…Ù„ÙØ§Ù‹ Ù„Ø£ÙØ­ØµÙ‡ (ØµÙˆØ±ØŒ Ù†ØµÙˆØµØŒ ÙƒÙˆØ¯)")
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"):
        st.session_state.messages = []
        st.rerun()

# --- ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø® ---
model, model_name = get_working_model()
if not model:
    st.error("âŒ Ø§Ù„Ù†Ø¸Ø§Ù… Ù…ØªÙˆÙ‚Ù. ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…ÙØªØ§Ø­.")
    st.stop()

# --- Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø§Øª ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # Ù„Ùˆ ÙÙŠÙ‡ Ù…Ù„ÙØ§Øª ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ØŒ Ù†Ø¹Ø±Ø¶Ù‡Ø§ Ù‡Ù†Ø§ (Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹)

# ================= Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£ÙˆØ§Ù…Ø± (Ù‚Ù„Ø¨ Ù‡ÙˆÙ†Ø¯Ø§) =================

if prompt := st.chat_input("Ø§Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ­ÙŠÙ„..."):
    # 1. Ø¹Ø±Ø¶ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. ØªÙÙƒÙŠØ± Ù‡ÙˆÙ†Ø¯Ø§ ÙˆØªÙ†ÙÙŠØ° Ø§Ù„Ø£ÙˆØ§Ù…Ø±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # --- Ø£) ÙØ­Øµ Ù‡Ù„ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ù…Ø±ÙÙ‚ØŸ ---
            file_context = ""
            if uploaded_file:
                try:
                    # Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù (Ù†ØµÙŠ)
                    stringio = uploaded_file.getvalue().decode("utf-8")
                    file_context = f"\n\n[USER UPLOADED FILE CONTENT]:\n{stringio}\n"
                    st.toast("ØªÙ… Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­! ğŸ“‚")
                except:
                    file_context = "\n[USER UPLOADED A BINARY FILE - I CAN SEE IT BUT NOT READ TEXT DIRECTLY YET]\n"

            # --- Ø¨) Ù‡Ù„ Ù‡Ø°Ø§ Ø·Ù„Ø¨ ØªØ·ÙˆÙŠØ± Ø°Ø§ØªÙŠØŸ (Evolve) ---
            dev_keywords = ["Ø·ÙˆØ± Ù†ÙØ³Ùƒ", "Ø¹Ø¯Ù„ Ø§Ù„ÙƒÙˆØ¯", "ØºÙŠØ± Ù„ÙˆÙ†", "ØºÙŠØ± Ø§Ù„Ø®Ù„ÙÙŠØ©", "Ø¶ÙŠÙ Ø®Ø§ØµÙŠØ©"]
            is_dev = any(k in prompt for k in dev_keywords)

            # --- Ø¬) Ù‡Ù„ Ù‡Ø°Ø§ Ø·Ù„Ø¨ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§ØªØŸ (Generate) ---
            gen_keywords = ["Ø§Ø¹Ù…Ù„ Ù…Ù„Ù", "Ø§ÙƒØªØ¨ Ù…Ù„Ù", "Ø§Ù†Ø´ÙŠØ¡", "Ø§ØµÙ†Ø¹", "pdf", "ØµÙˆØ±Ø©", "ÙƒÙˆØ¯"]
            is_gen = any(k in prompt for k in gen_keywords)

            if is_dev:
                message_placeholder.warning("âš™ï¸ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø·ÙˆØ±... Ø³Ø£Ù‚ÙˆÙ… Ø¨ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯ ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„.")
                
                # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ
                current_file = __file__
                with open(current_file, "r", encoding="utf-8") as f:
                    old_code = f.read()

                dev_prompt = f"""
                Act as an expert Streamlit Python Developer (Honda).
                User Request: "{prompt}"
                
                Current Code:
                ```python
                {old_code}
                ```
                
                MISSION: Rewrite the FULL code to implement the request.
                RULES:
                1. If user asks to change color, modify 'st.session_state.ui_color' or CSS.
                2. If user asks to add features, add standard Streamlit widgets.
                3. KEEP 'get_working_model' and 'clean_code_block' functions intact.
                4. Return ONLY valid Python code.
                """
                
                response = model.generate_content(dev_prompt)
                new_code = clean_code_block(response.text)
                
                # Ø§Ù„Ø­ÙØ¸ ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚
                if "import streamlit" in new_code and len(new_code) > 500:
                    with open(current_file, "w", encoding="utf-8") as f:
                        f.write(new_code)
                    message_placeholder.success("âœ… ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ«! Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…...")
                    time.sleep(1)
                    st.rerun()
                else:
                    message_placeholder.error("ÙØ´Ù„ Ø§Ù„ØªØ·ÙˆÙŠØ±: Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù†Ø§ØªØ¬ ØºÙŠØ± Ù…ÙƒØªÙ…Ù„.")

            elif is_gen:
                message_placeholder.info("ğŸ”¨ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©...")
                
                # Ù‡Ù†Ø§ Ù†Ø·Ù„Ø¨ Ù…Ù† Ù‡ÙˆÙ†Ø¯Ø§ ÙƒØªØ§Ø¨Ø© ÙƒÙˆØ¯ Ø¨Ø§ÙŠØ«ÙˆÙ† ÙŠØµÙ†Ø¹ Ø§Ù„Ù…Ù„Ù (PDF, Image, etc)
                gen_prompt = f"""
                Act as a Python Coding Assistant.
                User wants to create a file/program based on: "{prompt}"
                
                Write a COMPLETE Python script that uses standard libraries (like fpdf for pdf, matplotlib for images, etc.) to generate this file.
                The script should save the result to a file (e.g., output.txt, output.png).
                Use Streamlit to display/download the result if possible.
                
                Output ONLY the Python code to generate this.
                """
                
                response = model.generate_content(gen_prompt)
                code_to_run = clean_code_block(response.text)
                
                # Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙˆØ¯ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù„Ø£Ù†Ù†Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©ØŒ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø«Ù‚ÙŠÙ„Ø© Ù…Ù‚ÙŠØ¯ØŒ ÙØ§Ù„Ø£ÙØ¶Ù„ Ù†Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙˆØ¯)
                message_placeholder.markdown("Ù„Ù‚Ø¯ Ù‚Ù…Øª Ø¨ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø°ÙŠ ÙŠØµÙ†Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù. ÙŠÙ…ÙƒÙ†Ùƒ Ù†Ø³Ø®Ù‡ ÙˆØªØ´ØºÙŠÙ„Ù‡ØŒ Ø£Ùˆ Ø³Ø£Ø­Ø§ÙˆÙ„ ØªÙ†ÙÙŠØ°Ù‡ Ø§Ù„Ø¢Ù†:")
                st.code(code_to_run, language='python')
                
                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙ†ÙÙŠØ° Ø§Ù„ÙƒÙˆØ¯ (Sandbox execution - dangerous but requested)
                # Ù…Ù„Ø§Ø­Ø¸Ø©: ÙÙŠ Ø¨ÙŠØ¦Ø© Streamlit CloudØŒ Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¯ÙŠØ³Ùƒ Ù…Ø­Ø¯ÙˆØ¯Ø©
                # Ø³Ù†Ù‚ÙˆÙ… Ø¨Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„ØªÙ†ÙÙŠØ°
                try:
                    exec(code_to_run)
                    st.success("ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„ÙƒÙˆØ¯! (ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙˆØ§Ø¬Ù‡Ø©)")
                except Exception as e:
                    st.warning(f"ÙƒØªØ¨Øª Ø§Ù„ÙƒÙˆØ¯ Ù„ÙƒÙ† Ù„Ù… Ø£Ø³ØªØ·Ø¹ ØªØ´ØºÙŠÙ„Ù‡ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ù‡Ù†Ø§: {e}")
                
                full_response = "ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©."

            else:
                # --- Ø¯) Ø¯Ø±Ø¯Ø´Ø© Ø¹Ø§Ø¯ÙŠØ© ÙˆØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª ---
                chat_prompt = f"""
                Ø£Ù†Øª 'Ù‡ÙˆÙ†Ø¯Ø§'ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙˆÙ…Ø­ØªØ±Ù ÙˆÙ…Ø¨Ø±Ù…Ø¬.
                ØªØªØ­Ø¯Ø« Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø§Ù„ÙˆØ¯ÙˆØ¯Ø©.
                Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙ‚ (Ø¥Ù† ÙˆØ¬Ø¯): {file_context}
                
                Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {prompt}
                """
                response = model.generate_content(chat_prompt)
                full_response = response.text
                message_placeholder.markdown(full_response)

        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
            full_response = "Ø­Ø¯Ø« Ø®Ø·Ø£."

    # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    if not is_dev:
        st.session_state.messages.append({"role": "assistant", "content": full_response})
```

4.  Ø§Ø¶ØºØ· **Commit changes**.
