match = re.search(pattern, text, re.DOTALL)
if match: 
    return match.group(1).strip()
    return text.strip()

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø® Ø§Ù„Ø°ÙƒÙŠ (Ø¨Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©) ---
def get_working_model():
    try:
        if "HONDA_API_KEY" not in st.secrets:
            st.error("âš ï¸ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Secrets!")
            return None, "No Key"

        api_key = st.secrets["HONDA_API_KEY"]
        genai.configure(api_key=api_key)

        # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø© (Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙˆØ§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©)
        models_to_try = [
            'gemini-2.5-flash', 
            'gemini-2.5-flash-latest',
            'gemini-2.5-pro', 
            'gemini-2.5-pro-exp',
            'gemini-2-flash', 
            'gemini-2-pro',
            'gemini-3-flash', 
            'gemini-3-pro',
            'gemini-1.5-flash',          # Ø§Ù„Ø£Ø³Ø±Ø¹
            'gemini-1.5-flash-latest',
            'gemini-1.5-flash-001',
            'gemini-1.5-pro',
            'gemini-pro',
            # Ø§Ø­ØªÙŠØ§Ø·ÙŠ
            'models/gemini-1.5-flash', 'models/gemini-pro'
        ]

        # ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª
        for model_name in models_to_try:
            try:
                model = genai.GenerativeModel(model_name)
                return model, model_name
            except:
                continue 
        
        return genai.GenerativeModel('gemini-1.5-flash'), 'gemini-1.5-flash (Fallback)'

    except Exception as e:
        st.error(f"Ø®Ø·Ø£ Ø§ØªØµØ§Ù„: {e}")
        return None, str(e)

# --- ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… ---
model, model_name = get_working_model()

if model:
    st.caption(f"âœ… Ù…ØªØµÙ„ Ø¨Ù…Ø®: {model_name}")
else:
    st.caption("ğŸ”´ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ù…ØªØµÙ„")

# --- Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ø´Ø§Øª ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- Ø§Ù„ØªÙØ§Ø¹Ù„ ÙˆØ§Ù„Ø£ÙˆØ§Ù…Ø± ---
if prompt := st.chat_input("Ø£Ù…Ø±Ùƒ ÙŠØ§ Ø²Ø¹ÙŠÙ…..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        if not model:
            message_placeholder.error("Ø£Ù†Ø§ Ø¹Ø·Ù„Ø§Ù† Ø­Ø§Ù„ÙŠØ§Ù‹.")
            full_response = "Error."
        else:
            try:
                # --- Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠ (Self-Evolution) ---
                dev_keywords = ["Ø·ÙˆØ±", "Ø¹Ø¯Ù„", "Ø¶ÙŠÙ", "Ø§Ù…Ø³Ø­", "ÙƒÙˆØ¯", "Ø¨Ø±Ù†Ø§Ù…Ø¬", "Ø²Ø±Ø§Ø±", "Ø®Ø§ØµÙŠØ©"]
                is_dev = any(k in prompt for k in dev_keywords)

                if is_dev:
                    message_placeholder.warning("âš™ï¸ Ø¬Ø§Ø±ÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„Ù†Ø¸Ø§Ù… Ø°Ø§ØªÙŠØ§Ù‹... (Ù„Ø§ ØªØºÙ„Ù‚ Ø§Ù„ØµÙØ­Ø©)")
                    
                    # 1. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ
                    current_file = __file__
                    try:
                        with open(current_file, "r", encoding="utf-8") as f:
                            old_code = f.read()
                    except:
                        old_code = ""

                    # 2. Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØµØ§Ø±Ù… Ù„Ù„Ù…Ø·ÙˆØ±
                    dev_prompt = f"""
                    Act as an expert Python Streamlit Developer.
                    TASK: Rewrite the ENTIRE current code to implement this request: "{prompt}".
                    
                    CURRENT CODE:
                    ```python
                    {old_code}
                    ```
                    
                    CRITICAL RULES:
                    1. Return the FULL VALID PYTHON CODE only.
                    2. DO NOT include markdown backticks (```) if possible.
                    3. KEEP 'get_working_model' and 'models_to_try' list EXACTLY as is.
                    4. KEEP 'clean_code_block' function.
                    5. Ensure correct indentation (4 spaces).
                    """
                    
                    try:
                        response = model.generate_content(dev_prompt)
                        raw_code = response.text
                        
                        # 3. ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯
                        new_code = clean_code_block(raw_code)
                        
                        # 4. Ø§Ù„Ø­ÙØ¸ ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
                        if "import streamlit" in new_code and len(new_code) > 500:
                            with open(current_file, "w", encoding="utf-8") as f:
                                f.write(new_code)
                            
                            message_placeholder.success("âœ… ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ±! Ø¬Ø§Ø±ÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„...")
                            st.session_state.messages.append({"role": "assistant", "content": "ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ø¸Ø§Ù…."})
                            st.rerun()
                        else:
                            message_placeholder.error("ÙØ´Ù„ Ø§Ù„ØªØ·ÙˆÙŠØ±: Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù†Ø§ØªØ¬ ØºÙŠØ± Ø³Ù„ÙŠÙ….")
                            full_response = "ÙØ´Ù„."

                    except Exception as e:
                        if "429" in str(e):
                            message_placeholder.warning("â³ Ø¶ØºØ· Ø¹Ø§Ù„ÙŠØŒ Ø§Ø³ØªÙ†Ù‰ Ø¯Ù‚ÙŠÙ‚Ø©.")
                            full_response = "ØªÙˆÙ‚Ù Ù…Ø¤Ù‚Øª."
                        else:
                            st.error(f"Ø®Ø·Ø£ Ø¨Ø±Ù…Ø¬ÙŠ: {e}")
                            full_response = "ÙØ´Ù„."
                
                else:
                    # --- Ø§Ù„Ø´Ø§Øª Ø§Ù„Ø¹Ø§Ø¯ÙŠ ---
                    chat_prompt = f"Ø£Ù†Øª Ù‡ÙˆÙ†Ø¯Ø§ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ±ÙŠ Ø°ÙƒÙŠ. Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {prompt}"
                    response = model.generate_content(chat_prompt)
                    message_placeholder.markdown(response.text)
                    full_response = response.text

            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
                full_response = "Error."
            
        if not is_dev:
            st.session_state.messages.append({"role": "assistant", "content": full_response})
