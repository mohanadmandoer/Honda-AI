import streamlit as st
import google.generativeai as genai
import os

# ุฏุงูุฉ ุงูุชูุธูู (ูููุฉ ุนุดุงู ุงูุชุนุฏูู ูุดุชุบู)
def clean_code_block(text):
    # ูุณุชุฏุนู ููุชุจุฉ ุงูุชุนุจูุฑุงุช ุงูููุทูุฉ
    import re
    # ุจููููู ุฏูุฑ ุนูู ุฃู ููุงู ุจูู ุนูุงูุงุช ุงูููุฏ ุงูุซูุงุซูุฉ
    pattern = r
    http://googleusercontentcom/immersive_entry_chip

ุจุณ ูุฏู! ุจููุฉ ุงูููุฏ ุงููู ูู Honda4.py ุณููู ูููู ุฌุฒุก ุงูุฐุงูุฑุฉ (if "messages" not in st.session_state) ููุฌูุฏ ูู ููุงูู ุงูุตุญ ุชุญุช

ุงุนูู ุงูุชุนุฏูู ุงูุตุบูุฑ ุฏู ูุงุนูู Commit ูุงููููุน ููุดุชุบู ูุนุงู
  
def get_working_model():
    """ูุชุตู ุจุฃูุถู ููุฏูู ูุชุงุญ (ูุธุงู ุงูููุงุนุฉ ุถุฏ ุงูุชููู)"""
    try:
        if "HONDA_API_KEY" not in st.secrets:
            st.error("โ๏ธ ููุชุงุญ ุงูุชุดุบูู ุบูุฑ ููุฌูุฏ ูู Secrets!")
            return None, "No Key"

        api_key = st.secrets["HONDA_API_KEY"]
        genai.configure(api_key=api_key)

        # ูุงุฆูุฉ ุงูููุฏููุงุช ุงูุดุงููุฉ (ุงูุญุงุถุฑ ูุงููุณุชูุจู)
        models_to_try = [
            'gemini-2.5-flash',
            'gemini-2.5-flash-latest',
            'gemini-2.5-pro',
            'gemini-2.0-flash',
            'gemini-1.5-flash',
            'gemini-1.5-flash-latest',
            'gemini-1.5-pro',
            'gemini-3-flash',
            'gemini-3-flash-latest',
            'gemini-3-pro',
            'gemini-pro',
            'models/gemini-1.5-flash', 'models/gemini-pro'
        ]

        for model_name in models_to_try:
            try:
                model = genai.GenerativeModel(model_name)
                return model, model_name
            except:
                continue 
        
        return genai.GenerativeModel('gemini-1.5-flash'), 'Fallback'

    except Exception as e:
        st.error(f"ุฎุทุฃ ูู ุงูุงุชุตุงู: {e}")
        return None, str(e)

# ================= ูุงุฌูุฉ ุงููุณุชุฎุฏู =================

st.title("๐ค ูููุฏุง - ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงููุชุทูุฑ")
st.caption("ุฃูุง ุฃุทูุฑ ููุณูุ ุฃุตูุน ุงููููุงุชุ ูุฃุชุญูู ูู ูุธูุฑู.")

# --- ุงูุดุฑูุท ุงูุฌุงูุจู (ููุฃุฏูุงุช) ---
with st.sidebar:
    st.header("๐ ุฅุฏุงุฑุฉ ุงููููุงุช")
    uploaded_file = st.file_uploader("ุงุนุทูู ูููุงู ูุฃูุญุตู (ุตูุฑุ ูุตูุตุ ููุฏ)")
    
    if st.button("๐๏ธ ูุณุญ ุงูุฐุงูุฑุฉ"):
        st.session_state.messages = []
        st.rerun()

# --- ุชุดุบูู ุงููุฎ ---
model, model_name = get_working_model()
if not model:
    st.error("โ ุงููุธุงู ูุชููู. ุชุฃูุฏ ูู ุงูููุชุงุญ.")
    st.stop()

# --- ุชููุฆุฉ ุงูุฐุงูุฑุฉ (ุฏู ุงูุฌุฒุก ุงููุงูุต) ---
if "messages" not in st.session_state:
    st.session_state.messages = []
# >>>>>>>>>>>><<<<<<<<<<<<

# --- ุนุฑุถ ุงูุดุงุช ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # ูู ููู ูููุงุช ุชู ุฅูุดุงุคูุงุ ูุนุฑุถูุง ููุง (ูุณุชูุจูุงู)

# ================= ูุนุงูุฌุฉ ุงูุฃูุงูุฑ (ููุจ ูููุฏุง) =================

if prompt := st.chat_input("ุงุทูุจ ุงููุณุชุญูู..."):
    # 1. ุนุฑุถ ุทูุจ ุงููุณุชุฎุฏู
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. ุชูููุฑ ูููุฏุง ูุชูููุฐ ุงูุฃูุงูุฑ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # --- ุฃ) ูุญุต ูู ููุฌุฏ ููู ูุฑููุ ---
            file_context = ""
            if uploaded_file:
                try:
                    # ูุฑุงุกุฉ ูุญุชูู ุงูููู (ูุตู)
                    stringio = uploaded_file.getvalue().decode("utf-8")
                    file_context = f"\n\n[USER UPLOADED FILE CONTENT]:\n{stringio}\n"
                    st.toast("ุชู ูุฑุงุกุฉ ุงูููู ุจูุฌุงุญ! ๐")
                except:
                    file_context = "\n[USER UPLOADED A BINARY FILE - I CAN SEE IT BUT NOT READ TEXT DIRECTLY YET]\n"

            # --- ุจ) ูู ูุฐุง ุทูุจ ุชุทููุฑ ุฐุงุชูุ (Evolve) ---
            dev_keywords = ["ุทูุฑ ููุณู", "ุนุฏู ุงูููุฏ", "ุบูุฑ ููู", "ุบูุฑ ุงูุฎูููุฉ", "ุถูู ุฎุงุตูุฉ"]
            is_dev = any(k in prompt for k in dev_keywords)

            # --- ุฌ) ูู ูุฐุง ุทูุจ ุฅูุดุงุก ูููุงุชุ (Generate) ---
            gen_keywords = ["ุงุนูู ููู", "ุงูุชุจ ููู", "ุงูุดูุก", "ุงุตูุน", "pdf", "ุตูุฑุฉ", "ููุฏ"]
            is_gen = any(k in prompt for k in gen_keywords)

            if is_dev:
                message_placeholder.warning("โ๏ธ ุฌุงุฑู ุงูุฏุฎูู ููุถุน ุงููุทูุฑ... ุณุฃููู ุจุชุนุฏูู ุงูููุฏ ูุฅุนุงุฏุฉ ุงูุชุดุบูู.")
                
                # ูุฑุงุกุฉ ุงูููุฏ ุงูุญุงูู
                current_file = __file__
                with open(current_file, "r", encoding="utf-8") as f:
                    old_code = f.read()

                dev_prompt = f"""
                Act as an expert Streamlit Python Developer (Honda).
                User Request: "{prompt}"
                
                Current Code:
                ```python
                {old_code}
                ```
                
                MISSION: Rewrite the FULL code to implement the request.
                RULES:
                1. If user asks to change color, modify 'st.session_state.ui_color' or CSS.
                2. If user asks to add features, add standard Streamlit widgets.
                3. KEEP 'get_working_model' and 'clean_code_block' functions intact.
                4. Return ONLY valid Python code.
                """
                
                response = model.generate_content(dev_prompt)
                new_code = clean_code_block(response.text)
                
                # ุงูุญูุธ ูุงูุชุทุจูู
                if "import streamlit" in new_code and len(new_code) > 500:
                    with open(current_file, "w", encoding="utf-8") as f:
                        f.write(new_code)
                    message_placeholder.success("โ ุชู ุงูุชุญุฏูุซ! ุฅุนุงุฏุฉ ุชุดุบูู ุงููุธุงู...")
                    time.sleep(1)
                    st.rerun()
                else:
                    message_placeholder.error("ูุดู ุงูุชุทููุฑ: ุงูููุฏ ุงููุงุชุฌ ุบูุฑ ููุชูู.")

            elif is_gen:
                message_placeholder.info("๐จ ุฌุงุฑู ุงูุนูู ุนูู ุฅูุดุงุก ุงููููุงุช ุงููุทููุจุฉ...")
                
                # ููุง ูุทูุจ ูู ูููุฏุง ูุชุงุจุฉ ููุฏ ุจุงูุซูู ูุตูุน ุงูููู (PDF, Image, etc)
                gen_prompt = f"""
                Act as a Python Coding Assistant.
                User wants to create a file/program based on: "{prompt}"
                
                Write a COMPLETE Python script that uses standard libraries (like fpdf for pdf, matplotlib for images, etc.) to generate this file.
                The script should save the result to a file (e.g., output.txt, output.png).
                Use Streamlit to display/download the result if possible.
                
                Output ONLY the Python code to generate this.
                """
                
                response = model.generate_content(gen_prompt)
                code_to_run = clean_code_block(response.text)
                
                # ุนุฑุถ ุงูููุฏ ูููุณุชุฎุฏู (ูุฃููุง ุนูู ุงูุณุญุงุจุฉุ ุงูุชุดุบูู ุงููุจุงุดุฑ ูููููุงุช ุงูุซูููุฉ ูููุฏุ ูุงูุฃูุถู ูุนุฑุถ ุงูููุฏ)
                message_placeholder.markdown("ููุฏ ููุช ุจูุชุงุจุฉ ุงูุจุฑูุงูุฌ ุงูุฐู ูุตูุน ูุฐุง ุงูููู. ููููู ูุณุฎู ูุชุดุบูููุ ุฃู ุณุฃุญุงูู ุชูููุฐู ุงูุขู:")
                st.code(code_to_run, language='python')
                
                # ูุญุงููุฉ ุชูููุฐ ุงูููุฏ (Sandbox execution - dangerous but requested)
                # ููุงุญุธุฉ: ูู ุจูุฆุฉ Streamlit Cloudุ ุงููุชุงุจุฉ ุนูู ุงูุฏูุณู ูุญุฏูุฏุฉ
                # ุณูููู ุจูุญุงููุฉ ุจุณูุทุฉ ููุชูููุฐ
                try:
                    exec(code_to_run)
                    st.success("ุชู ุชูููุฐ ุงูููุฏ! (ุชุญูู ูู ุงููุชูุฌุฉ ุฅุฐุง ูุงูุช ูุงุฌูุฉ)")
                except Exception as e:
                    st.warning(f"ูุชุจุช ุงูููุฏ ููู ูู ุฃุณุชุทุน ุชุดุบููู ุจุงููุงูู ููุง: {e}")
                
                full_response = "ุชูุช ุงููุนุงูุฌุฉ."

            else:
                # --- ุฏ) ุฏุฑุฏุดุฉ ุนุงุฏูุฉ ูุชุญููู ูููุงุช ---
                chat_prompt = f"""
                ุฃูุช 'ูููุฏุง'ุ ูุณุงุนุฏ ุฐูู ููุญุชุฑู ููุจุฑูุฌ.
                ุชุชุญุฏุซ ุจุงูููุฌุฉ ุงููุตุฑูุฉ ุงููุฏูุฏุฉ.
                ุณูุงู ุงูููู ุงููุฑูู (ุฅู ูุฌุฏ): {file_context}
                
                ุณุคุงู ุงููุณุชุฎุฏู: {prompt}
                """
                response = model.generate_content(chat_prompt)
                full_response = response.text
                message_placeholder.markdown(full_response)

        except Exception as e:
            st.error(f"ุญุฏุซ ุฎุทุฃ ุบูุฑ ูุชููุน: {e}")
            full_response = "ุญุฏุซ ุฎุทุฃ."

    # ุญูุธ ูู ุงูุฐุงูุฑุฉ
    if not is_dev:
        st.session_state.messages.append({"role": "assistant", "content": full_response})
