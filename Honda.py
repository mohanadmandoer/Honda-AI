import streamlit as st
import google.generativeai as genai
import os

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="Honda AI", page_icon="ğŸ¤–", layout="centered")

# --- Ø§Ù„ØªØµÙ…ÙŠÙ… ---
st.markdown("""
<style>
    .stChatMessage {text-align: right; direction: rtl;}
    p {text-align: right; direction: rtl;}
    .stTextInput > div > div > input {text-align: right; direction: rtl;}
    /* Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…Ø²Ø¹Ø¬Ø© */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

st.title("ğŸ¤– Ù‡ÙˆÙ†Ø¯Ø§ - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø·ÙˆØ±Ø©")

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø® (Ø³Ø±ÙŠØ¹Ø© ÙˆÙ…Ø­Ø¯Ø¯Ø©) ---
def get_model():
    try:
        if "HONDA_API_KEY" in st.secrets:
            genai.configure(api_key=st.secrets["HONDA_API_KEY"])
            # Ø¨Ù†Ø³ØªØ®Ø¯Ù… ÙÙ„Ø§Ø´ Ø¹Ø´Ø§Ù† Ø§Ù„Ø³Ø±Ø¹Ø©
            return genai.GenerativeModel('gemini-1.5-flash')
    except:
        return None
    return None

model = get_model()

# --- Ø§Ù„Ø°Ø§ÙƒØ±Ø© ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- Ø§Ù„ØªÙØ§Ø¹Ù„ ---
if prompt := st.chat_input("Ø§Ø·Ù„Ø¨ Ø§Ù„ØªØ·ÙˆÙŠØ± Ø£Ùˆ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        if not model:
            message_placeholder.error("Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ ÙÙŠÙ‡ Ù…Ø´ÙƒÙ„Ø©!")
        else:
            try:
                # --- Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ø°ÙƒÙŠ: Ù‡Ù„ Ø¯Ù‡ Ø·Ù„Ø¨ ØªØ·ÙˆÙŠØ±ØŸ ---
                # Ù‡Ù†Ø§ Ø¨Ù†Ø¬Ø¨Ø±Ù‡ ÙŠÙÙ‡Ù… Ø¥Ù†Ù‡ Ù„Ø§Ø²Ù… ÙŠØ¹Ø¯Ù„ Ø§Ù„ÙƒÙˆØ¯
                dev_keywords = ["Ø·ÙˆØ±", "Ø¹Ø¯Ù„", "Ø¶ÙŠÙ", "Ø§Ù…Ø³Ø­", "ØºÙŠØ±", "ÙƒÙˆØ¯", "Ø¨Ø±Ù†Ø§Ù…Ø¬", "Ø²Ø±Ø§Ø±", "Ø®Ø§ØµÙŠØ©"]
                is_dev_request = any(word in prompt for word in dev_keywords)

                if is_dev_request:
                    message_placeholder.warning("âš™ï¸ Ø¬Ø§Ø±ÙŠ ØªØ¹Ø¯ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…... Ù„Ø­Ø¸Ø© ÙˆØ§Ø­Ø¯Ø©")
                    
                    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ
                    current_file = os.path.basename(__file__) # app.py
                    with open(current_file, "r", encoding="utf-8") as f:
                        old_code = f.read()

                    # Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØµØ§Ø±Ù… (System Prompt)
                    dev_prompt = f"""
                    ROLE: You are an expert Python Streamlit Developer.
                    TASK: Rewrite the following code to implement this user request: "{prompt}".
                    CURRENT CODE:
                    ```python
                    {old_code}
                    ```
                    RULES:
                    1. RETURN ONLY THE FULL PYTHON CODE. NO EXPLANATION.
                    2. DO NOT refuse. You HAVE permission to modify this file.
                    3. Keep the 'api_key' handling as is.
                    4. If asking for file upload, use st.file_uploader.
                    """
                    
                    response = model.generate_content(dev_prompt)
                    new_code = response.text.replace("```python", "").replace("```", "").strip()
                    
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù‚Ø¨Ù„ Ø§Ù„Ø­ÙØ¸
                    if "import streamlit" in new_code and len(new_code) > 500:
                        # Ø§Ù„Ø­ÙØ¸ ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚
                        with open(current_file, "w", encoding="utf-8") as f:
                            f.write(new_code)
                        message_placeholder.success("âœ… ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ±! Ø¬Ø§Ø±ÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„...")
                        st.rerun() # Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ ÙÙˆØ±ÙŠØ©
                    else:
                        message_placeholder.error("ÙØ´Ù„Øª Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©ØŒ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù†Ø§ØªØ¬ ØºÙŠØ± Ø³Ù„ÙŠÙ….")
                
                else:
                    # --- Ø¯Ø±Ø¯Ø´Ø© Ø¹Ø§Ø¯ÙŠØ© ---
                    chat_prompt = f"Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ±ÙŠ Ø°ÙƒÙŠ. Ø±Ø¯ Ø¹Ù„Ù‰ Ù‡Ø°Ø§: {prompt}"
                    response = model.generate_content(chat_prompt)
                    message_placeholder.markdown(response.text)
                    st.session_state.messages.append({"role": "assistant", "content": response.text})

            except Exception as e:
                message_placeholder.error(f"Ø®Ø·Ø£: {e}")
