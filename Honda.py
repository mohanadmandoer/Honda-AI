def clean_code_block(text):
    pattern = r"```python(.*?)```"
    match = re.search(pattern, text, re.DOTALL)
    if match:
        return match.group(1).strip()
    return text.strip()

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø® Ø§Ù„Ø°ÙƒÙŠ ---
def get_working_model():
    try:
        if "HONDA_API_KEY" not in st.secrets:
            st.error("âš ï¸ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Secrets!")
            return None, "No Key"

        api_key = st.secrets["HONDA_API_KEY"]
        genai.configure(api_key=api_key)

        # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø© (Ø²ÙŠ Ù…Ø§ Ø·Ù„Ø¨Øª Ø¨Ø§Ù„Ø¸Ø¨Ø·)
        models_to_try = [
            'models/gemini-2.5-flash',
            'models/gemini-2.5-flash-latest',
            'models/gemini-2.5-flash-001',
            'models/gemini-2.5-pro',
            'models/gemini-2-flash',
            'models/gemini-2-flash-latest',
            'models/gemini-2-flash-001',
            'models/gemini-2-pro',
            'models/gemini-3-flash',
            'models/gemini-3-flash-latest',
            'models/gemini-3-flash-001',
            'models/gemini-3-pro',
            'gemini-1.5-flash',
            'gemini-1.5-flash-latest',
            'gemini-1.5-flash-001',
            'gemini-1.5-pro',
            'gemini-pro',
        ]

        for model_name in models_to_try:
            try:
                model = genai.GenerativeModel(model_name)
                return model, model_name
            except:
                continue 
        
        return genai.GenerativeModel('gemini-1.5-flash'), 'gemini-1.5-flash (Fallback)'

    except Exception as e:
        return None, str(e)

# --- ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… ---
model, model_name = get_working_model()

if model:
    st.caption(f"âœ… Ù…ØªØµÙ„ Ø¨Ù…Ø®: {model_name}")
else:
    st.caption("ğŸ”´ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ù…ØªØµÙ„")

# --- Ø§Ù„Ø°Ø§ÙƒØ±Ø© ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- Ø§Ù„ØªÙØ§Ø¹Ù„ ---
if prompt := st.chat_input("Ø£Ù…Ø±Ùƒ ÙŠØ§ Ø²Ø¹ÙŠÙ…..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        if not model:
            message_placeholder.error("Ø£Ù†Ø§ Ø¹Ø·Ù„Ø§Ù† Ø­Ø§Ù„ÙŠØ§Ù‹.")
            full_response = "Error."
        else:
            try:
                # --- Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠ ---
                dev_keywords = ["Ø·ÙˆØ±", "Ø¹Ø¯Ù„", "Ø¶ÙŠÙ", "Ø§Ù…Ø³Ø­", "ÙƒÙˆØ¯", "Ø¨Ø±Ù†Ø§Ù…Ø¬", "Ø²Ø±Ø§Ø±", "Ø®Ø§ØµÙŠØ©"]
                is_dev = any(k in prompt for k in dev_keywords)

                if is_dev:
                    message_placeholder.warning("âš™ï¸ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠ... (Ù„Ø­Ø¸Ø© ÙˆØ§Ø­Ø¯Ø©)")
                    
                    try:
                        current_file = __file__
                        with open(current_file, "r", encoding="utf-8") as f:
                            old_code = f.read()
                    except:
                        old_code = ""

                    dev_prompt = f"""
                    Act as an expert Python Streamlit Developer.
                    TASK: Rewrite the ENTIRE current code to implement this request: "{prompt}".
                    
                    CURRENT CODE:
                    ```python
                    {old_code}
                    ```
                    
                    CRITICAL RULES:
                    1. Return the FULL VALID PYTHON CODE only.
                    2. KEEP 'get_working_model' and 'models_to_try' list EXACTLY as is.
                    3. KEEP 'clean_code_block' function.
                    4. Ensure correct indentation (4 spaces).
                    """
                    
                    try:
                        response = model.generate_content(dev_prompt)
                        new_code = clean_code_block(response.text)
                        
                        if "import streamlit" in new_code and len(new_code) > 500:
                            with open(current_file, "w", encoding="utf-8") as f:
                                f.write(new_code)
                            
                            message_placeholder.success("âœ… ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ±! Ø¬Ø§Ø±ÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„...")
                            st.rerun()
                        else:
                            message_placeholder.error("ÙØ´Ù„ Ø§Ù„ØªØ·ÙˆÙŠØ±: Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù†Ø§ØªØ¬ ØºÙŠØ± Ø³Ù„ÙŠÙ….")
                            full_response = "ÙØ´Ù„."

                    except Exception as e:
                        st.error(f"Ø®Ø·Ø£ Ø¨Ø±Ù…Ø¬ÙŠ: {e}")
                        full_response = "ÙØ´Ù„."
                
                else:
                    # --- Ø§Ù„Ø´Ø§Øª Ø§Ù„Ø¹Ø§Ø¯ÙŠ ---
                    chat_prompt = f"Ø£Ù†Øª Ù‡ÙˆÙ†Ø¯Ø§ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ±ÙŠ Ø°ÙƒÙŠ. Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {prompt}"
                    response = model.generate_content(chat_prompt)
                    message_placeholder.markdown(response.text)
                    full_response = response.text

            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
                full_response = "Error."
            
        if not is_dev:
            st.session_state.messages.append({"role": "assistant", "content": full_response})
