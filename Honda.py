import streamlit as st
import google.generativeai as genai
import os

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="Honda AI", page_icon="ğŸ¤–", layout="centered")

# --- Ø§Ù„ØªØµÙ…ÙŠÙ… ---
st.markdown("""
<style>
    .stChatMessage {text-align: right; direction: rtl;}
    p {text-align: right; direction: rtl;}
    .stTextInput > div > div > input {text-align: right; direction: rtl;}
</style>
""", unsafe_allow_html=True)

# --- Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ---
st.title("ğŸ¤– Ù‡ÙˆÙ†Ø¯Ø§ - Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠ")
st.caption("Ø´ØºØ§Ù„ Ø¨Ù…ÙˆØ¯ÙŠÙ„ gemini-pro Ø§Ù„Ù…Ø³ØªÙ‚Ø± âœ…")

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ---
try:
    if "HONDA_API_KEY" in st.secrets:
        api_key = st.secrets["HONDA_API_KEY"]
        genai.configure(api_key=api_key)
        # Ù‡Ù†Ø§ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø¶Ù…ÙˆÙ† Ø¹Ø´Ø§Ù† Ù†Ù…Ù†Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        model = genai.GenerativeModel('gemini-pro')
    else:
        st.error("âš ï¸ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Secrets!")
except Exception as e:
    st.error(f"Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ù…ÙØªØ§Ø­: {e}")

# --- Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø´Ø§Øª ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø§Øª ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- Ø§Ù„ØªÙØ§Ø¹Ù„ ---
if prompt := st.chat_input("Ø§Ø·Ù„Ø¨ Ù…Ù†ÙŠ Ø£ÙŠ Ø­Ø§Ø¬Ø© ÙŠØ§ Ø²Ø¹ÙŠÙ…..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        try:
            # Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ·ÙˆÙŠØ±
            if "Ø·ÙˆØ± Ù†ÙØ³Ùƒ" in prompt or "Ø§ÙƒØªØ¨ ÙƒÙˆØ¯" in prompt:
                full_response = "Ø¬Ø§Ø±ÙŠ ÙƒØªØ§Ø¨Ø© Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯...\n"
                ai_prompt = f"Ø£Ù†Øª Ø®Ø¨ÙŠØ± Streamlit. Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ±ÙŠØ¯: {prompt}. Ø§ÙƒØªØ¨ ÙƒÙˆØ¯ python ÙƒØ§Ù…Ù„ Ù„Ù…Ù„Ù app.py."
                response = model.generate_content(ai_prompt)
                message_placeholder.markdown(response.text)
                full_response = response.text
            else:
                # Ø¯Ø±Ø¯Ø´Ø© Ø¹Ø§Ø¯ÙŠØ©
                chat_prompt = f"Ø£Ù†Øª Ù‡ÙˆÙ†Ø¯Ø§ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ±ÙŠ Ø°ÙƒÙŠ ÙˆÙ…Ø±Ø­. Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {prompt}"
                response = model.generate_content(chat_prompt)
                message_placeholder.markdown(response.text)
                full_response = response.text
        except Exception as e:
            st.error(f"âš ï¸ Ø®Ø·Ø£: {e}")
            full_response = "Ø­ØµÙ„Øª Ù…Ø´ÙƒÙ„Ø©ØŒ Ø¬Ø±Ø¨ ØªØ§Ù†ÙŠ."
            
    st.session_state.messages.append({"role": "assistant", "content": full_response})
